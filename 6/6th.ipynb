{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6vzmgGIxehy",
        "outputId": "b4d102ff-3c91-4665-c38b-d2a7955ef6a5"
      },
      "source": [
        "from random import seed\r\n",
        "from random import randrange\r\n",
        "from csv import reader\r\n",
        "from math import exp\r\n",
        "\r\n",
        "\r\n",
        "def load_csv(filename):\r\n",
        "\tdataset = list()\r\n",
        "\twith open(filename, 'r') as file:\r\n",
        "\t\tcsv_reader = reader(file)\r\n",
        "\t\tfor row in csv_reader:\r\n",
        "\t\t\tif not row:\r\n",
        "\t\t\t\tcontinue\r\n",
        "\t\t\tdataset.append(row)\r\n",
        "\treturn dataset\r\n",
        "\r\n",
        "def str_column_to_float(dataset, column):\r\n",
        "\tfor row in dataset:\r\n",
        "\t\trow[column] = float(row[column].strip())\r\n",
        "\r\n",
        "def dataset_minmax(dataset):\r\n",
        "\tminmax = list()\r\n",
        "\tfor i in range(len(dataset[0])):\r\n",
        "\t\tcol_values = [row[i] for row in dataset]\r\n",
        "\t\tvalue_min = min(col_values)\r\n",
        "\t\tvalue_max = max(col_values)\r\n",
        "\t\tminmax.append([value_min, value_max])\r\n",
        "\treturn minmax\r\n",
        "\r\n",
        "def normalize_dataset(dataset, minmax):\r\n",
        "\tfor row in dataset:\r\n",
        "\t\tfor i in range(len(row)):\r\n",
        "\t\t\trow[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\r\n",
        "\r\n",
        "def cross_validation_split(dataset, n_folds):\r\n",
        "\tdataset_split = list()\r\n",
        "\tdataset_copy = list(dataset)\r\n",
        "\tfold_size = int(len(dataset) / n_folds)\r\n",
        "\tfor i in range(n_folds):\r\n",
        "\t\tfold = list()\r\n",
        "\t\twhile len(fold) < fold_size:\r\n",
        "\t\t\tindex = randrange(len(dataset_copy))\r\n",
        "\t\t\tfold.append(dataset_copy.pop(index))\r\n",
        "\t\tdataset_split.append(fold)\r\n",
        "\treturn dataset_split\r\n",
        "\r\n",
        "def accuracy_metric(actual, predicted):\r\n",
        "\tcorrect = 0\r\n",
        "\tfor i in range(len(actual)):\r\n",
        "\t\tif actual[i] == predicted[i]:\r\n",
        "\t\t\tcorrect += 1\r\n",
        "\treturn correct / float(len(actual)) * 100.0\r\n",
        "\r\n",
        "\r\n",
        "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\r\n",
        "\tfolds = cross_validation_split(dataset, n_folds)\r\n",
        "\tscores = list()\r\n",
        "\tfor fold in folds:\r\n",
        "\t\ttrain_set = list(folds)\r\n",
        "\t\ttrain_set.remove(fold)\r\n",
        "\t\ttrain_set = sum(train_set, [])\r\n",
        "\t\ttest_set = list()\r\n",
        "\t\tfor row in fold:\r\n",
        "\t\t\trow_copy = list(row)\r\n",
        "\t\t\ttest_set.append(row_copy)\r\n",
        "\t\t\trow_copy[-1] = None\r\n",
        "\t\tpredicted = algorithm(train_set, test_set, *args)\r\n",
        "\t\tactual = [row[-1] for row in fold]\r\n",
        "\t\taccuracy = accuracy_metric(actual, predicted)\r\n",
        "\t\tscores.append(accuracy)\r\n",
        "\treturn scores\r\n",
        "\r\n",
        "\r\n",
        "def predict(row, coefficients):\r\n",
        "\tyhat = coefficients[0]\r\n",
        "\tfor i in range(len(row)-1):\r\n",
        "\t\tyhat += coefficients[i + 1] * row[i]\r\n",
        "\treturn 1.0 / (1.0 + exp(-yhat))\r\n",
        "\r\n",
        "def coefficients_sgd(train, l_rate, n_epoch):\r\n",
        "\tcoef = [0.0 for i in range(len(train[0]))]\r\n",
        "\tfor epoch in range(n_epoch):\r\n",
        "\t\tfor row in train:\r\n",
        "\t\t\tyhat = predict(row, coef)\r\n",
        "\t\t\terror = row[-1] - yhat\r\n",
        "\t\t\tcoef[0] = coef[0] + l_rate * error * yhat * (1.0 - yhat)\r\n",
        "\t\t\tfor i in range(len(row)-1):\r\n",
        "\t\t\t\tcoef[i + 1] = coef[i + 1] + l_rate * error * yhat * (1.0 - yhat) * row[i]\r\n",
        "\treturn coef\r\n",
        "\r\n",
        "\r\n",
        "def logistic_regression(train, test, l_rate, n_epoch):\r\n",
        "\tpredictions = list()\r\n",
        "\tcoef = coefficients_sgd(train, l_rate, n_epoch)\r\n",
        "\tfor row in test:\r\n",
        "\t\tyhat = predict(row, coef)\r\n",
        "\t\tyhat = round(yhat)\r\n",
        "\t\tpredictions.append(yhat)\r\n",
        "\treturn(predictions) \r\n",
        "\r\n",
        "\r\n",
        "seed(1)\r\n",
        "\r\n",
        "filename = '/content/Student-University.csv'\r\n",
        "dataset = load_csv(filename)\r\n",
        "for i in range(len(dataset[0])):\r\n",
        "\tstr_column_to_float(dataset, i)\r\n",
        "# normalize\r\n",
        "minmax = dataset_minmax(dataset)\r\n",
        "normalize_dataset(dataset, minmax)\r\n",
        "\r\n",
        "n_folds = 5\r\n",
        "l_rate = 0.1\r\n",
        "n_epoch = 100\r\n",
        "scores = evaluate_algorithm(dataset, logistic_regression, n_folds, l_rate, n_epoch)\r\n",
        "print('Scores: %s' % scores)\r\n",
        "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))\r\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scores: [95.0, 90.0, 85.0, 95.0, 90.0]\n",
            "Mean Accuracy: 91.000%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}