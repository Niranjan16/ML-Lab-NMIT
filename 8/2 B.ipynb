{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yf0c-NVIwf_Z",
        "outputId": "0458824d-ee3a-443b-94ff-c8e1620a1c5e"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.model_selection import train_test_split # Import train_test_split function\r\n",
        "from sklearn import svm #Import svm model\r\n",
        "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "\r\n",
        "data = pd.read_csv(\"/content/heart.csv - heart.csv.csv\")\r\n",
        "\r\n",
        "x = data.drop('target',axis = 1) \r\n",
        "y = data.target\r\n",
        "\r\n",
        "#split the test set and train set\r\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3,random_state=109) \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#Create a svm Classifier\r\n",
        "ml = svm.SVC(kernel='linear') # Linear Kernel\r\n",
        "\r\n",
        "#Train the model using the training sets\r\n",
        "ml.fit(x_train, y_train)\r\n",
        "\r\n",
        "#Predict the response for test dataset\r\n",
        "y_pred = ml.predict(x_test)\r\n",
        "\r\n",
        "\r\n",
        "# Model Accuracy: how often is the classifier correct?\r\n",
        "#print(ml.score(x_test,y_test))\r\n",
        "cm = confusion_matrix(y_test,y_pred)\r\n",
        "print('\\n'.join([''.join(['{:4}'.format(item) for item in row]) for row in cm]))\r\n",
        "                \r\n",
        "FP = cm.sum(axis=0) - np.diag(cm)\r\n",
        "FN = cm.sum(axis=1) - np.diag(cm)\r\n",
        "TP = np.diag(cm)\r\n",
        "TN = cm.sum() - (FP + FN + TP)\r\n",
        "print('False Positives\\n {}'.format(FP))\r\n",
        "print('False Negetives\\n {}'.format(FN))\r\n",
        "print('True Positives\\n {}'.format(TP))\r\n",
        "print('True Negetives\\n {}'.format(TN))\r\n",
        "TPR = TP/(TP+FN)\r\n",
        "print('Sensitivity \\n {}'.format(TPR))\r\n",
        "TNR = TN/(TN+FP)\r\n",
        "print('Specificity \\n {}'.format(TNR))\r\n",
        "Precision = TP/(TP+FP)\r\n",
        "print('Precision \\n {}'.format(Precision))\r\n",
        "Recall = TP/(TP+FN)\r\n",
        "print('Recall \\n {}'.format(Recall))\r\n",
        "Acc = (TP+TN)/(TP+TN+FP+FN)\r\n",
        "print('Áccuracy \\n{}'.format(Acc))\r\n",
        "Fscore = 2*(Precision*Recall)/(Precision+Recall)\r\n",
        "print('FScore \\n{}'.format(Fscore))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  35   5\n",
            "   4  47\n",
            "False Positives\n",
            " [4 5]\n",
            "False Negetives\n",
            " [5 4]\n",
            "True Positives\n",
            " [35 47]\n",
            "True Negetives\n",
            " [47 35]\n",
            "Sensitivity \n",
            " [0.875      0.92156863]\n",
            "Specificity \n",
            " [0.92156863 0.875     ]\n",
            "Precision \n",
            " [0.8974359  0.90384615]\n",
            "Recall \n",
            " [0.875      0.92156863]\n",
            "Áccuracy \n",
            "[0.9010989 0.9010989]\n",
            "FScore \n",
            "[0.88607595 0.91262136]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}